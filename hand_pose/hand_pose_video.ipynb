{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocal-applicant",
   "metadata": {},
   "source": [
    "# OpenVINO Hand Pose Demo\n",
    "\n",
    "Source: https://github.com/PINTO0309/PINTO_model_zoo model 033_Hand_Detection_and_Tracking\n",
    "\n",
    "Model License: Apache\n",
    "\n",
    "This notebook demonstrates doing inference on a hand tracking model with a webcam video.\n",
    "\n",
    "This is a work-in-progress demo. To run it, you need to install openvino and opencv-python.\n",
    "\n",
    "You may need to adjust the camera_index in the settings.\n",
    "\n",
    "Click the Jupyter \"stop\" button (the red square at the top of the notebook) to stop the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "soviet-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from io import BytesIO\n",
    "\n",
    "import cv2\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from openvino.inference_engine import IECore\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-premium",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "logical-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxml = \"./models/hand_landmark_fp16/hand_landmark.xml\"\n",
    "modelxml = \"./models/hand_landmark_new_fp16/hand_landmark_new.xml\"\n",
    "modelbin = modelxml.replace(\"xml\", \"bin\")\n",
    "\n",
    "colors = [(255, 0, 0), (255, 255, 0), (255, 0, 255), (0, 255, 255), (0, 255, 0)]\n",
    "camera_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-concrete",
   "metadata": {},
   "source": [
    "## Set up Inference Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "important-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "\n",
    "net = ie.read_network(model=modelxml, weights=modelbin)\n",
    "\n",
    "exec_net = ie.load_network(net, \"CPU\")\n",
    "input_blob = next(iter(exec_net.input_info))\n",
    "output_key = list(exec_net.outputs.keys())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-threat",
   "metadata": {},
   "source": [
    "## Define functions for inference and showing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minus-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(frame):\n",
    "    inputim = frame / 255\n",
    "    inputim = np.expand_dims(inputim.transpose(2, 0, 1), 0)\n",
    "    result = exec_net.infer({input_blob: inputim})[output_key].squeeze()\n",
    "    coordinates = np.split(result, 21)\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suspended-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showarray(a, prev_display_id=None, fmt=\"jpeg\"):\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    obj = IPython.display.Image(data=f.getvalue())\n",
    "    if prev_display_id is not None:\n",
    "        IPython.display.update_display(obj, display_id=prev_display_id)\n",
    "        return prev_display_id\n",
    "    else:\n",
    "        return IPython.display.display(obj, display_id=True).display_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-istanbul",
   "metadata": {},
   "source": [
    "## Go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tight-cancer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first = True\n",
    "prev = 0\n",
    "frame_rate = 5\n",
    "previndex = -1\n",
    "ret = True\n",
    "display_id = None\n",
    "input_size = 256\n",
    "\n",
    "cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "try:\n",
    "    while ret:\n",
    "\n",
    "        time_elapsed = time.time() - prev\n",
    "\n",
    "        if time_elapsed > 1.0 / frame_rate:\n",
    "            prev = time.time()\n",
    "\n",
    "            # Read frame from webcam\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            width = frame.shape[1]\n",
    "            height = frame.shape[0]\n",
    "\n",
    "            # Resize to input size\n",
    "            resized_frame = cv2.resize(frame, (input_size, input_size))\n",
    "            result = inference(resized_frame)\n",
    "\n",
    "            # Process the results and draw points and lines over the frame\n",
    "            for i, point in enumerate(result):\n",
    "\n",
    "                # Every 4 points is a new finger with a separate color\n",
    "                index = (i - 1) // 4\n",
    "                if i > 0:\n",
    "                    color = colors[index]\n",
    "                else:\n",
    "                    color = (0, 0, 0)  # First landmark is the palm of the hand\n",
    "\n",
    "                cv2.circle(\n",
    "                    frame,\n",
    "                    (\n",
    "                        int(point[0] / input_size * width),\n",
    "                        int(point[1] / input_size * height),\n",
    "                    ),\n",
    "                    int(2 * frame.shape[1] / 256),\n",
    "                    color,\n",
    "                    -1,\n",
    "                )\n",
    "\n",
    "                # Draw lines between landmark points\n",
    "                if previndex == index:\n",
    "\n",
    "                    cv2.line(\n",
    "                        frame,\n",
    "                        (\n",
    "                            int(result[0][0] / input_size * width),\n",
    "                            int(result[0][1] / input_size * height),\n",
    "                        ),\n",
    "                        (\n",
    "                            int(result[index * 4 + 1][0] / input_size * width),\n",
    "                            int(result[index * 4 + 1][1] / input_size * height),\n",
    "                        ),\n",
    "                        color,\n",
    "                    )\n",
    "                    cv2.line(\n",
    "                        frame,\n",
    "                        (\n",
    "                            int(result[i - 1][0] / input_size * width),\n",
    "                            int(result[i - 1][1] / input_size * height),\n",
    "                        ),\n",
    "                        (\n",
    "                            int(result[i][0] / input_size * width),\n",
    "                            int(result[i][1] / input_size * height),\n",
    "                        ),\n",
    "                        color,\n",
    "                    )\n",
    "                previndex = index\n",
    "\n",
    "            display_id = showarray(frame, None if display_id is None else display_id)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    IPython.display.clear_output(wait=False)\n",
    "    cap.release()\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ovvenv",
   "language": "python",
   "name": "ovvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
