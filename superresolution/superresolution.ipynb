{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "configured-reporter",
   "metadata": {},
   "source": [
    "# ENHANCE! \n",
    "\n",
    "## Super Resolution with OpenVINO\n",
    "\n",
    "WORK IN PROGRESS NOTEBOOK NOT READY AND FOR PUBLIC RELEASE\n",
    "\n",
    "[Super Resolution Model description](https://github.com/openvinotoolkit/open_model_zoo/blob/develop/models/intel/single-image-super-resolution-1032/description/single-image-super-resolution-1032.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-ranch",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-johnson",
   "metadata": {},
   "source": [
    "### Install requirements\n",
    "\n",
    "Uncomment the cell below to install the Python packages that are required to run this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --quiet --index-url https://test.pypi.org/simple --extra-index-url https://pypi.org/simple openvino-dev\n",
    "# ! pip install matplotlib youtube_dl Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-voluntary",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib\n",
    "from base64 import b64encode\n",
    "from pathlib import Path, PurePosixPath\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "from openvino.inference_engine import IECore\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-month",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/single-image-super-resolution-1032/FP16/single-image-super-resolution-1032.xml\"\n",
    "device = \"CPU\"\n",
    "\n",
    "model_name = os.path.basename(model_url)\n",
    "model_xml = f\"models/{model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-trouble",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clean up, add comments and make more robust!\n",
    "def resize_and_pad(image, input_shape, interpolation=None):\n",
    "    \"\"\"\n",
    "    Resize image to input_shape (width, height), preserving aspect ratio, adding padding where necessary\n",
    "    \"\"\"\n",
    "    if image.shape[:2] == input_shape[::-1]:\n",
    "        return image\n",
    "    else:\n",
    "        target_width, target_height = input_shape\n",
    "        height_multi = target_height / image.shape[0]\n",
    "        width_multi = target_width / image.shape[1]\n",
    "        multi = min(width_multi, height_multi)\n",
    "        multi_dimension = np.argmin((height_multi, width_multi))\n",
    "        new_target_width = int(round(image.shape[1] * multi))\n",
    "        new_target_height = int(round(image.shape[0] * multi))\n",
    "\n",
    "        resized_image = cv2.resize(image, (new_target_width, new_target_height), interpolation=interpolation)\n",
    "        if target_width / target_height != image.shape[2] / image.shape[1]:\n",
    "            # Aspect ratio of image is not the same as aspect ratio of target: add padding\n",
    "            if multi_dimension == 0:  # pad width\n",
    "                index = (target_width - resized_image.shape[1]) // 2\n",
    "                pad = ((0, 0), (index, index + (target_width - resized_image.shape[1]) % 2), (0, 0))\n",
    "            else:  # pad height\n",
    "                index = (target_height - resized_image.shape[0]) // 2\n",
    "                pad = ((index, index + (target_height - resized_image.shape[0]) % 2), (0, 0), (0, 0))\n",
    "            padded = np.pad(resized_image, pad, mode=\"constant\")\n",
    "        else:\n",
    "            padded = resized_image\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-netherlands",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_text_on_image(image, text):\n",
    "    \"\"\"\n",
    "    Write the specified text in the top left corner of the image\n",
    "    \"\"\"\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    org = (20, 20)\n",
    "    font_scale = 4\n",
    "    font_color = (255, 255, 255)\n",
    "    line_type = 1\n",
    "    font_thickness = 2\n",
    "    text_color_bg = (0, 0, 0)\n",
    "    x, y = org\n",
    "    \n",
    "    image = cv2.UMat(image)\n",
    "    (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    result_im = cv2.rectangle(image, org, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "\n",
    "    textim = cv2.putText(image, text, (x, y + text_h + font_scale - 1), font, font_scale, font_color, font_thickness, line_type)\n",
    "    return textim.get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ir_model(model_xml_url, directory):\n",
    "    \"\"\"\n",
    "    Downloads IR model from `model_xml_url` and save it to `directory` with the same filename. The directory will be\n",
    "    created if it does not exist.\n",
    "    \"\"\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    model_name = os.path.basename(model_xml_url)\n",
    "    model_xml_path =  f\"{directory}/{model_name}\"\n",
    "    urllib.request.urlretrieve(model_xml_url, model_xml_path)\n",
    "    urllib.request.urlretrieve(model_xml_url[:-4] + \".bin\", f\"{model_xml_path[:-4]}.bin\")\n",
    "    print(f\"Model {model_name} downloaded to {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str):\n",
    "    \"\"\"\n",
    "    Loads an image from `path` and returns it as BGR numpy array. `path` should point to an image file,\n",
    "    either a local filename or an url.\n",
    "    \"\"\"\n",
    "    if path.startswith('http'):\n",
    "        # Set User-Agent to Mozilla because some websites block requests with User-Agent Python\n",
    "        request = urllib.request.Request(path, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response = urllib.request.urlopen(request)\n",
    "        array = np.asarray(bytearray(response.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(array, -1)  # Loads the image as BGR\n",
    "    else:\n",
    "        image = cv2.imread(path)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-animation",
   "metadata": {},
   "source": [
    "## Download and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_ir_model(model_url, \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-assets",
   "metadata": {},
   "source": [
    "Load the model in Inference Engine with `ie.read_network` and load it to the specified device with `ie.load_network`\n",
    "\n",
    "The Super Resolution model expects two inputs: 1) the input image, 2) a bicubic interpolation of the input image to a size of 1920x1080. It returns the super resolution version of the image in 1920x180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(model=model_xml, weights=model_xml.replace(\"xml\", \"bin\"))\n",
    "exec_net = ie.load_network(network=net, device_name=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network inputs and outputs are dictionaries. Get the keys for the dictionaries.\n",
    "original_image_key = list(exec_net.input_info)[0]\n",
    "bicubic_image_key = list(exec_net.input_info)[1]\n",
    "output_key = list(exec_net.outputs.keys())[0]\n",
    "\n",
    "# Get the expected input and target shape. `.dims[2:]` returns the height and width. OpenCV's resize function\n",
    "# expects the shape as (width, height), so we reverse the shape with `[::-1]` and convert it to a tuple\n",
    "input_height, input_width = tuple(exec_net.input_info[\"0\"].tensor_desc.dims[2:])\n",
    "target_height, target_width = tuple(exec_net.input_info[\"1\"].tensor_desc.dims[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-disposition",
   "metadata": {},
   "source": [
    "## Single Image Super Resolution\n",
    "\n",
    "### Download, load, resize and reshape input image\n",
    "\n",
    "The input image is read with OpenCV, resized to network input size, and reshaped to (N,C,H,W) (H=height, W=width, C=number of channels, N=number of images). The image is also resized to network output size, with bicubic interpolation. This bicubic image is the second input to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source: https://www.flickr.com/people/roland/ via https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&r=false&c=%2Fm%2F0k4j&id=531b67238c25813b CC BY 2.0\n",
    "# image_path can point to a local filename or a URL (starting with \"http\")\n",
    "image_path = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Bled_(9783636305).jpg/170px-Bled_(9783636305).jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image.\n",
    "image = load_image(image_path)\n",
    "\n",
    "# The network expects landscape images. If the input image is portrait, rotate it before\n",
    "# propagating through the network\n",
    "portrait = False\n",
    "if image.shape[0] > image.shape[1]:\n",
    "    portrait = True\n",
    "    image = cv2.rotate(image, 2)\n",
    "\n",
    "# Resize the image to network input shape\n",
    "resized_image = resize_and_pad(image, (input_width, input_height))\n",
    "# Reshape the image from (H,W,C) to (N,C,H,W)\n",
    "input_image_original = np.expand_dims(resized_image.transpose(2, 0, 1), axis=0)\n",
    "\n",
    "# Resize the image to the target shape with bicubic interpolation\n",
    "bicubic_image = resize_and_pad(image, (target_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "input_image_bicubic = np.expand_dims(bicubic_image.transpose(2, 0, 1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-tiffany",
   "metadata": {},
   "source": [
    "### Do inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-madrid",
   "metadata": {},
   "source": [
    "Make a function that converts the superresolution network result to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result_to_image(result):\n",
    "    \"\"\"\n",
    "    Convert network result of floating point numbers to image with integer values from 0-255\n",
    "    result is expected to be a single network result in N,C,H,W shape\n",
    "    \"\"\"\n",
    "    result = result.squeeze(0).transpose(1, 2, 0)\n",
    "    result *= 255\n",
    "    result[result < 0] = 0\n",
    "    result[result > 255] = 255\n",
    "    result = result.astype(np.uint8) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do inference\n",
    "network_result = exec_net.infer(inputs={original_image_key: input_image_original, bicubic_image_key: input_image_bicubic})\n",
    "# Reshape inference result to image shape and data type\n",
    "result = network_result[output_key]\n",
    "result = convert_result_to_image(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if portrait:\n",
    "    # Rotate image and result back to portrait mode\n",
    "    result = cv2.rotate(result, 0)\n",
    "    bicubic_image = cv2.rotate(bicubic_image, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-chick",
   "metadata": {},
   "source": [
    "### Show result\n",
    "\n",
    "DEBUG: Showing subtraction of bicubic and super resolution version for testing purposes\n",
    "TODO: remove padding from visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(30, 15))\n",
    "ax[0].imshow(bicubic_image[:, :, (2, 1, 0)])  # (2,1,0) converts image from BGR to RGB\n",
    "ax[1].imshow(result[:, :, (2, 1, 0)])\n",
    "ax[2].imshow(bicubic_image - result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-glucose",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Write animated gif with bicubic/superresolution comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-original",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add text with \"SUPER\" or \"BICUBIC\" to the superresolution or bicubic image\n",
    "image_super = write_text_on_image(result, \"SUPER\")\n",
    "image_bicubic = write_text_on_image(bicubic_image, \"BICUBIC\")\n",
    "\n",
    "# Store the image and the results in IMAGE_DIR\n",
    "IMAGE_DIR = \"images\"\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "original_image_path = Path(IMAGE_DIR)/os.path.basename(image_path)\n",
    "superres_image_path = original_image_path.with_name(f\"{original_image_path.stem}_superres{original_image_path.suffix}\")\n",
    "bicubic_image_path = original_image_path.with_name(f\"{original_image_path.stem}_bicubic{original_image_path.suffix}\")\n",
    "\n",
    "cv2.imwrite(str(original_image_path), image)\n",
    "cv2.imwrite(str(superres_image_path), image_super)\n",
    "cv2.imwrite(str(bicubic_image_path), image_bicubic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-forty",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_pil = Image.fromarray(image_super[:, :, (2, 1, 0)])\n",
    "bicubic_pil = Image.fromarray(image_bicubic[:, :, (2, 1, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_image_path = original_image_path.with_name(f\"{original_image_path.stem}_comparison.gif\")\n",
    "\n",
    "result_pil.save(fp=str(gif_image_path), format=\"GIF\", append_images=[bicubic_pil,], save_all=True, duration=1000, loop=0)\n",
    "DisplayImage(str(gif_image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-marble",
   "metadata": {},
   "source": [
    "## Superresolution on Video\n",
    "\n",
    "DEBUG: Uses Youtube_DL for quickly downloading a video from Youtube. \n",
    "TODO: save audio to enhanced file\n",
    "\n",
    "Reads first 1200 frames from video. Change NUM_FRAMES below to modify this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-tulsa",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = \"videos\"\n",
    "VIDEO_NAME = \"pat.mp4\"\n",
    "# Number of frames to read from the input video. Set to 0 to read all frames.\n",
    "NUM_FRAMES = 100\n",
    "\n",
    "# The format for saving the result video's\n",
    "# DEBUG: find good format/extension that works well across all platforms\n",
    "FOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-congo",
   "metadata": {},
   "source": [
    "Download video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = Path(os.path.join(VIDEO_DIR, VIDEO_NAME))\n",
    "\n",
    "# Use youtube_dl to download a video. It downloads to the videos subdirectory. \n",
    "# You can also place a local video there and comment out the following lines\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=V8yS3WIkOrA\"\n",
    "with youtube_dl.YoutubeDL({\"outtmpl\": str(video_path)}) as ydl:\n",
    "    ydl.download([VIDEO_URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-technology",
   "metadata": {},
   "source": [
    "Open the video and read the first frame to get FPS, and frame dimensions, and determine if video is in portrait mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(str(video_path))\n",
    "_, image = cap.read()\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "FRAME_HEIGHT, FRAME_WIDTH = image.shape[:2]\n",
    "if FRAME_HEIGHT > FRAME_WIDTH:\n",
    "    PORTRAIT = True\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-superior",
   "metadata": {},
   "source": [
    "Create superresolution video, bicubic video and comparison video. The superresolution video contains the enhanced video, upsampled with superresolution, the bicubic video is the input video upsampled with bicubic interpolation, the combination video sets the bicubic video and the superresolution side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(VIDEO_DIR, exist_ok=True)\n",
    "superres_video_path = video_path.with_name(f\"{video_path.stem}_superres.avi\")\n",
    "bicubic_video_path = video_path.with_name(f\"{video_path.stem}_bicubic.avi\")\n",
    "comparison_video_path = video_path.with_name(f\"{video_path.stem}_comparison.avi\")\n",
    "\n",
    "superres_video = cv2.VideoWriter(str(superres_video_path), FOURCC, FPS, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "bicubic_video = cv2.VideoWriter(str(bicubic_video_path), FOURCC, FPS, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "comparison_video = cv2.VideoWriter(str(comparison_video_path), FOURCC, FPS, (FRAME_WIDTH * 2, FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-transaction",
   "metadata": {},
   "source": [
    "Read all video frames and ENHANCE them. Save the superresolution video, the bicubic video and the comparison video to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "frame_nr = 0\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        if NUM_FRAMES > 0 and frame_nr == NUM_FRAMES:\n",
    "            break\n",
    "        if portrait:\n",
    "            # resize to landscape\n",
    "            image = cv2.rotate(image, 2)\n",
    "\n",
    "        # Resize the image to network input shape\n",
    "        resized_image = resize_and_pad(image, (input_width, input_height))\n",
    "        # Reshape the image from (H,W,C) to (N,C,H,W)\n",
    "        input_image_original = np.expand_dims(resized_image.transpose(2, 0, 1), axis=0)\n",
    "\n",
    "        # Resize the image to the target shape with bicubic interpolation\n",
    "        bicubic_image = resize_and_pad(image, (target_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "        input_image_bicubic = np.expand_dims(bicubic_image.transpose(2, 0, 1), axis=0)\n",
    "\n",
    "        # Do inference\n",
    "        result = exec_net.infer(inputs={original_image_key: input_image_original, bicubic_image_key: input_image_bicubic})[output_key]\n",
    "\n",
    "        # Transform inference result into frame\n",
    "        result = convert_result_to_image(result)\n",
    "        # Write result frame and bicubic frame to video\n",
    "        superres_video.write(result)\n",
    "        bicubic_video.write(bicubic_image)\n",
    "        stacked_frame = np.hstack((bicubic_image, result))\n",
    "        comparison_video.write(stacked_frame)\n",
    "        frame_nr = frame_nr + 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Processing interrupted.\")\n",
    "finally:\n",
    "    superres_video.release()\n",
    "    bicubic_video.release()\n",
    "    comparison_video.release()\n",
    "    end_time = time.perf_counter()\n",
    "    duration = end_time - start_time\n",
    "    print(\n",
    "        f\"Video's saved to {VIDEO_DIR} directory. Processed {frame_nr} frames in {duration:.2f} seconds (Including frame processing and video loading/saving). {frame_nr/duration} frames per second\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-spirituality",
   "metadata": {},
   "source": [
    "### Show side-by-side video of bicubic and superresolution version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(str(comparison_video_path))\n",
    "display_handle = display(None, display_id=True)\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            display_handle.update(DisplayImage(data=cv2.imencode(\".jpeg\", frame)[1]))\n",
    "        else:\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-ministry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
