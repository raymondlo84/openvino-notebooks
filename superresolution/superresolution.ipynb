{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mighty-baking",
   "metadata": {},
   "source": [
    "# ENHANCE! \n",
    "\n",
    "## Super Resolution with OpenVINO\n",
    "\n",
    "WORK IN PROGRESS NOTEBOOK NOT READY AND FOR PUBLIC RELEASE\n",
    "\n",
    "[Super Resolution Model description](https://github.com/openvinotoolkit/open_model_zoo/blob/develop/models/intel/single-image-super-resolution-1032/description/single-image-super-resolution-1032.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-compact",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-spell",
   "metadata": {},
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --quiet --index-url https://test.pypi.org/simple --extra-index-url https://pypi.org/simple openvino-dev\n",
    "# ! pip install matplotlib youtube_dl Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-premiere",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from base64 import b64encode\n",
    "from pathlib import Path, PurePosixPath\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "from openvino.inference_engine import IECore\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-connecticut",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/single-image-super-resolution-1032/FP16/single-image-super-resolution-1032.xml\"\n",
    "device = \"CPU\"\n",
    "\n",
    "model_name = os.path.basename(model_url)\n",
    "model_xml = f\"models/{model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-speaking",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clean up, add comments and make more robust!\n",
    "def resize_and_pad(image, input_shape, interpolation=None):\n",
    "    \"\"\"\n",
    "    Resize image to input_shape (width, height), preserving aspect ratio, adding padding where necessary\n",
    "    \"\"\"\n",
    "    if image.shape[:2] == input_shape[::-1]:\n",
    "        return image\n",
    "    else:\n",
    "        target_width, target_height = input_shape\n",
    "        height_multi = target_height / image.shape[0]\n",
    "        width_multi = target_width / image.shape[1]\n",
    "        multi = min(width_multi, height_multi)\n",
    "        multi_dimension = np.argmin((height_multi, width_multi))\n",
    "        new_target_width = int(round(image.shape[1] * multi))\n",
    "        new_target_height = int(round(image.shape[0] * multi))\n",
    "\n",
    "        resized_image = cv2.resize(image, (new_target_width, new_target_height), interpolation=interpolation)\n",
    "        if target_width / target_height != image.shape[2] / image.shape[1]:\n",
    "            # Aspect ratio of image is not the same as aspect ratio of target: add padding\n",
    "            if multi_dimension == 0:  # pad width\n",
    "                index = (target_width - resized_image.shape[1]) // 2\n",
    "                pad = ((0, 0), (index, index + (target_width - resized_image.shape[1]) % 2), (0, 0))\n",
    "            else:  # pad height\n",
    "                index = (target_height - resized_image.shape[0]) // 2\n",
    "                pad = ((index, index + (target_height - resized_image.shape[0]) % 2), (0, 0), (0, 0))\n",
    "            padded = np.pad(resized_image, pad, mode=\"constant\")\n",
    "        else:\n",
    "            padded = resized_image\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-lotus",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_text_on_image(image, text):\n",
    "    \"\"\"\n",
    "    Write the specified text in the top left corner of the image\n",
    "    \"\"\"\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    org = (20, 20)\n",
    "    font_scale = 4\n",
    "    font_color = (255, 255, 255)\n",
    "    line_type = 1\n",
    "    font_thickness = 2\n",
    "    text_color_bg = (0, 0, 0)\n",
    "    x, y = org\n",
    "\n",
    "    (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    result_im = cv2.rectangle(image, org, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "\n",
    "    textim = cv2.putText(image, text, (x, y + text_h + font_scale - 1), font, font_scale, font_color, font_thickness, line_type)\n",
    "    return textim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-nickname",
   "metadata": {},
   "source": [
    "## Download and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(model_url, f\"models/{model_name}\")\n",
    "urllib.request.urlretrieve(model_url[:-4] + \".bin\", f\"models/{model_name[:-4]}.bin\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-niagara",
   "metadata": {},
   "source": [
    "Load the model in Inference Engine with `ie.read_network` and load it to the specified device with `ie.load_network`\n",
    "\n",
    "The Super Resolution model expects two inputs: 1) the input image, 2) a bicubic interpolation of the input image to a size of 1920x1080. It returns the super resolution version of the image in 1920x180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(model=model_xml, weights=model_xml.replace(\"xml\", \"bin\"))\n",
    "exec_net = ie.load_network(network=net, device_name=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network inputs and outputs are dictionaries. Get the keys for the dictionaries.\n",
    "original_image_key = list(exec_net.input_info)[0]\n",
    "bicubic_image_key = list(exec_net.input_info)[1]\n",
    "output_key = list(exec_net.outputs.keys())[0]\n",
    "\n",
    "# Get the expected input and target shape. `.dims[2:]` returns the height and width. OpenCV's resize function\n",
    "# expects the shape as (width, height), so we reverse the shape with `[::-1]` and convert it to a tuple\n",
    "input_height, input_width = tuple(exec_net.input_info[\"0\"].tensor_desc.dims[2:])\n",
    "target_height, target_width = tuple(exec_net.input_info[\"1\"].tensor_desc.dims[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-drain",
   "metadata": {},
   "source": [
    "## Single Image Super Resolution\n",
    "\n",
    "### Download, load, resize and reshape input image\n",
    "\n",
    "The input image is read with OpenCV, resized to network input size, and reshaped to (N,C,H,W) (H=height, W=width, C=number of channels, N=number of images). The image is also resized to network output size, with bicubic interpolation. This bicubic image is the second input to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source: https://www.flickr.com/people/roland/ via https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&r=false&c=%2Fm%2F0k4j&id=531b67238c25813b CC BY 2.0\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Bled_(9783636305).jpg/170px-Bled_(9783636305).jpg\"\n",
    "image_dir = \"images\"\n",
    "image_filename = \"image.jpg\"\n",
    "\n",
    "image_path = os.path.join(image_dir, image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(image_url, f\"{image_path}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image.\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# The network expects landscape images. If the input image is portrait, rotate it before\n",
    "# propagating through the network\n",
    "portrait = False\n",
    "if image.shape[0] > image.shape[1]:\n",
    "    portrait = True\n",
    "    image = cv2.rotate(image, 2)\n",
    "\n",
    "# Resize the image to network input shape\n",
    "resized_image = resize_and_pad(image, (input_width, input_height))\n",
    "# Reshape the image from (H,W,C) to (N,C,H,W)\n",
    "input_image_original = np.expand_dims(resized_image.transpose(2, 0, 1), axis=0)\n",
    "\n",
    "# Resize the image to the target shape with bicubic interpolation\n",
    "bicubic_image = resize_and_pad(image, (target_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "input_image_bicubic = np.expand_dims(bicubic_image.transpose(2, 0, 1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-medicine",
   "metadata": {},
   "source": [
    "### Do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do inference\n",
    "network_result = exec_net.infer(inputs={original_image_key: input_image_original, bicubic_image_key: input_image_bicubic})\n",
    "# Reshape inference result to image shape and data type\n",
    "result = network_result[output_key].squeeze(0).transpose(1, 2, 0) * 255\n",
    "result[result < 0] = 0\n",
    "result[result > 255] = 255\n",
    "result = result.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "if portrait:\n",
    "    # Rotate image and result back to portrait mode\n",
    "    result = cv2.rotate(result, 0)\n",
    "    bicubic_image = cv2.rotate(bicubic_image, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-accident",
   "metadata": {},
   "source": [
    "### Show result\n",
    "\n",
    "DEBUG: Showing subtraction of bicubic and super resolution version for testing purposes\n",
    "TODO: remove padding from visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(30, 15))\n",
    "ax[0].imshow(bicubic_image[:,:,(2,1,0)])\n",
    "ax[1].imshow(result[:,:,(2,1,0)])\n",
    "ax[2].imshow(bicubic_image - result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-interpretation",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Write animated gif with bicubic/superresolution comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-columbia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_super = write_text_on_image(cv2.UMat(result), \"SUPER\")\n",
    "image_bicubic = write_text_on_image(bicubic_image, \"BICUBIC\")\n",
    "cv2.imwrite(f\"{image_path[:-4]}_enhanced.jpg\", image_super)\n",
    "cv2.imwrite(f\"{image_path[:-4]}_bicubic.jpg\", image_bicubic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-actress",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_pil = Image.fromarray(image_super.get()[:,:,(2,1,0)])\n",
    "bicubic_pil = Image.fromarray(image_bicubic[:,:,(2,1,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_filename = f\"{image_path[:-4]}_comparison.gif\"\n",
    "result_pil.save(\n",
    "    fp=gif_filename,\n",
    "    format=\"GIF\",\n",
    "    append_images=[\n",
    "        bicubic_pil,\n",
    "    ],\n",
    "    save_all=True,\n",
    "    duration=1000,\n",
    "    loop=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayImage(gif_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-tiger",
   "metadata": {},
   "source": [
    "## Superresolution on Video\n",
    "\n",
    "DEBUG: Uses Youtube_DL for quickly downloading a video from Youtube. \n",
    "\n",
    "Reads first 1200 frames from video. Change NUM_FRAMES below to modify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 1200\n",
    "\n",
    "# Use youtube_dl to download a video. It downloads to the videos subdirectory. You can also place a local video there and comment out the last three lines\n",
    "video_dir = \"videos\"\n",
    "video_name = \"pat.mp4\"\n",
    "video_path = os.path.join(video_dir, video_name)\n",
    "\n",
    "# Comment this out if the video in video_path already exists\n",
    "video_url = \"https://www.youtube.com/watch?v=V8yS3WIkOrA\"\n",
    "with youtube_dl.YoutubeDL({\"outtmpl\": video_path}) as ydl:\n",
    "    ydl.download([video_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "portrait = False\n",
    "i = 0\n",
    "\n",
    "# Read all video frames and ENHANCE them. Save the bicubic upsampled and superresolution frames to resultlist and bicubiclist\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    i = i + 1\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "    if i == 1:\n",
    "        # Get video dimensions and determine if video is in portrait mode\n",
    "        frame_height, frame_width = image.shape[:2]\n",
    "        if frame_height > frame_width:\n",
    "            portrait = True\n",
    "\n",
    "        # Create video's to write the results to\n",
    "        superres_video = cv2.VideoWriter(\n",
    "            f\"{video_path[:-4]}_superres.avi\",\n",
    "            cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\"),\n",
    "            cap.get(cv2.CAP_PROP_FPS) / 2,\n",
    "            (frame_width, frame_height),\n",
    "        )\n",
    "        bicubic_video = cv2.VideoWriter(\n",
    "            f\"{video_path[:-4]}_bicubic.avi\",\n",
    "            cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\"),\n",
    "            cap.get(cv2.CAP_PROP_FPS) / 2,\n",
    "            (frame_width, frame_height),\n",
    "        )\n",
    "        stacked_video = cv2.VideoWriter(\n",
    "            f\"{video_path[:-4]}_stacked.avi\",\n",
    "            cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\"),\n",
    "            cap.get(cv2.CAP_PROP_FPS) / 2,\n",
    "            (frame_width * 2, frame_height),\n",
    "        )\n",
    "\n",
    "    if i == NUM_FRAMES:\n",
    "        break\n",
    "    if portrait:\n",
    "        # resize to landscape\n",
    "        image = cv2.rotate(image, 2)\n",
    "\n",
    "    # Resize the image to network input shape\n",
    "    resized_image = resize_and_pad(image, (input_width, input_height))\n",
    "    # Reshape the image from (H,W,C) to (N,C,H,W)\n",
    "    input_image_original = np.expand_dims(resized_image.transpose(2, 0, 1), axis=0)\n",
    "\n",
    "    # Resize the image to the target shape with bicubic interpolation\n",
    "    bicubic_image = resize_and_pad(image, (target_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "    input_image_bicubic = np.expand_dims(bicubic_image.transpose(2, 0, 1), axis=0)\n",
    "\n",
    "    # Do inference\n",
    "    result = exec_net.infer(inputs={original_image_key: input_image_original, bicubic_image_key: input_image_bicubic})[output_key].squeeze(\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Transform inference result into frame\n",
    "    result = result.transpose(1, 2, 0) * 255\n",
    "    result[result > 255] = 255\n",
    "    result[result < 0] = 0\n",
    "    result = result.astype(np.uint8)\n",
    "\n",
    "    # Write result frame and bicubic frame to video\n",
    "    superres_video.write(result)\n",
    "    bicubic_video.write(bicubic_image)\n",
    "    stacked_frame = np.hstack((bicubic_image, result))\n",
    "    stacked_video.write(stacked_frame)\n",
    "\n",
    "superres_video.release()\n",
    "bicubic_video.release()\n",
    "stacked_video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-association",
   "metadata": {},
   "source": [
    "### Compress and show video\n",
    "\n",
    "DEBUG: remove ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_video_path = f\"{video_path[:-4]}_stacked.avi\"\n",
    "\n",
    "compressed_video_path = stacked_video_path + \"_compressed.mp4\"\n",
    "! ffmpeg -i $stacked_video_path -vcodec libx264 $compressed_video_path -hide_banner -loglevel error -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4 = open(compressed_video_path, \"rb\").read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=1200 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"\n",
    "    % data_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-india",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
