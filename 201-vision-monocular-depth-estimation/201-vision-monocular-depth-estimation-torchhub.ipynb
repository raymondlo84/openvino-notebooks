{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "norman-catholic",
   "metadata": {
    "id": "moved-collapse"
   },
   "source": [
    "# MONODEPTH on Torch Hub ONNX model\n",
    "\n",
    "WORK IN PROGRESS NOTEBOOK NOT FOR PUBLIC RELEASE\n",
    "\n",
    "https://pytorch.org/hub/intelisl_midas_v2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-witch",
   "metadata": {
    "id": "creative-cisco"
   },
   "source": [
    "## Preparation \n",
    "\n",
    "### Install required Python\\* packages\n",
    "\n",
    "Run the cell below to install the Python\\* packages necessary to run this demo. After installing the packages you can delete this cell. Note that installation may take a while. There is no progress indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-liberia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grand-monster",
    "outputId": "ffdf9a92-f4f2-44cb-c0f8-780a64320167"
   },
   "outputs": [],
   "source": [
    "# # OpenVINO\n",
    "# !pip install --quiet --index-url https://test.pypi.org/simple --extra-index-url https://pypi.org/simple openvino-dev\n",
    "# # PyTorch - see https://pytorch.org/get-started for other options\n",
    "# !pip install --quiet  torch==1.8.0+cpu torchvision==0.9.0+cpu  -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# # Other packages\n",
    "# !pip install --quiet matplotlib youtube_dl Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-timeline",
   "metadata": {
    "id": "faced-honolulu"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-monaco",
   "metadata": {
    "id": "ahead-spider"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import urllib\n",
    "from base64 import b64encode\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import youtube_dl\n",
    "from IPython.display import HTML\n",
    "from openvino.inference_engine import IECore\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-bryan",
   "metadata": {
    "id": "contained-office"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-rebound",
   "metadata": {
    "id": "amber-lithuania"
   },
   "outputs": [],
   "source": [
    "precision = \"FP16\"\n",
    "device = \"CPU\"\n",
    "model_name = \"MiDaS_small\"\n",
    "# model_name = \"MiDaS\"\n",
    "onnx_model_name = model_name + \".onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-influence",
   "metadata": {
    "id": "cordless-closing"
   },
   "source": [
    "## Load model from Torch Hub and convert to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-state",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166,
     "referenced_widgets": [
      "5a17730c8f304656b8f2fe0a790a0234",
      "9e96e7aa16e94ce6a2408c3f43a700d6",
      "a956486853774f789419cf9824172729",
      "6da63a08b00543c1af578ad8e1e8969d",
      "e140391f225640329e8b9344e7fc0b5c",
      "8faae420e9c94233abf9286699de2fc0",
      "64a7cfc7cb084f4582e420737ff3f9f4",
      "a0db7c0f890b4fae887c9068d25377dd"
     ]
    },
    "id": "fancy-domain",
    "outputId": "3720dca7-c2bf-43d8-89db-a762d20f5553"
   },
   "outputs": [],
   "source": [
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_name, progress=False)\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "if \"small\" in model_name:\n",
    "    transform = midas_transforms.small_transform\n",
    "else:\n",
    "    transform = midas_transforms.default_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-synthetic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "circular-plumbing",
    "outputId": "e95eff04-5435-49d5-c3b2-b88bf3a3b2a3"
   },
   "outputs": [],
   "source": [
    "dummy_input = np.random.rand(800, 800, 3)\n",
    "dummy_input = transform(dummy_input)\n",
    "torch.onnx.export(midas, dummy_input, onnx_model_name, opset_version=11)\n",
    "print(dummy_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-output",
   "metadata": {
    "id": "sensitive-wagner"
   },
   "source": [
    "## Load model and get model information\n",
    "\n",
    "Load the model in Inference Engine with `ie.read_network` and load it to the specified device with `ie.load_network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-george",
   "metadata": {
    "id": "complete-brother"
   },
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(onnx_model_name)\n",
    "exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "\n",
    "input_key = list(exec_net.input_info)[0]\n",
    "output_key = list(exec_net.outputs.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-rouge",
   "metadata": {
    "id": "compact-bargain"
   },
   "source": [
    "## Monodepth on Image\n",
    "\n",
    "### Load, resize and reshape input image\n",
    "\n",
    "The input image is read with OpenCV, resized to network input size, and reshaped to (N,C,H,W) (H=height, W=width, C=number of channels, N=number of images). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-cheat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "central-psychology",
    "outputId": "d864ee96-3fbd-488d-da1a-88e730f34aad"
   },
   "outputs": [],
   "source": [
    "# Download and load an image\n",
    "# Image source: https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&r=false&c=%2Fm%2F02rgn06&id=470c2f96cb938855\n",
    "image_url = r\"https://farm6.staticflickr.com/3880/15127053318_be969c3a58_o.jpg\"\n",
    "urllib.request.urlretrieve(image_url, \"image.jpg\")\n",
    "\n",
    "\n",
    "image = cv2.imread(\"image.jpg\")[:, :, (2, 1, 0)]  # (2,1,0) changes the channels from BGR to RGB\n",
    "input_image = transform(image)\n",
    "input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-officer",
   "metadata": {
    "id": "wicked-intervention"
   },
   "outputs": [],
   "source": [
    "# reshape the network to the image size\n",
    "net.reshape({input_key: input_image.shape})\n",
    "exec_net = ie.load_network(network=net, device_name=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-saint",
   "metadata": {
    "id": "taken-spanking"
   },
   "source": [
    "### Do inference on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-jackson",
   "metadata": {
    "id": "banner-kruger"
   },
   "outputs": [],
   "source": [
    "result = exec_net.infer(inputs={input_key: input_image})[output_key].squeeze(0)\n",
    "resized_result = cv2.resize(\n",
    "    result, image.shape[:2][::-1]\n",
    ")  # resize back to original image shape. cv2.resize expects shape in (width, height), [::-1] reverses the (height, width) shape to match this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-broad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "ranging-executive",
    "outputId": "30373e8e-34e9-4820-e32d-764aa99d4b25"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(30, 15))\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(resized_result);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-thesis",
   "metadata": {
    "id": "descending-cache"
   },
   "source": [
    "## Monodepth on Video\n",
    "\n",
    "DEBUG: Uses Youtube_DL for quickly downloading a video from Youtube. Current video is not meant as demo video!\n",
    "\n",
    "Reads first 100 frames from video. Change NUM_FRAMES below to modify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-baptist",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "terminal-dividend",
    "outputId": "87f5ada0-8caf-49c3-fe54-626e2b1967f3"
   },
   "outputs": [],
   "source": [
    "NUM_FRAMES = 100\n",
    "\n",
    "# Use youtube_dl to download a video. It downloads to the videos subdirectory. You can also place a local video there and comment out the last three lines\n",
    "video_dir = \"videos\"\n",
    "video_name = \"pink\"\n",
    "video_ext = \".mkv\"  #DEBUG\n",
    "download_video_path = os.path.join(video_dir, video_name)\n",
    "video_path = download_video_path + video_ext\n",
    "\n",
    "# Comment this out if the video in video_path already exists\n",
    "video_url = \"https://youtu.be/BMDxbn5HDf8\"\n",
    "with youtube_dl.YoutubeDL({\"outtmpl\": download_video_path, \"start_time\":45}) as ydl:\n",
    "    ydl.download([video_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-mention",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "present-albany",
    "outputId": "600edb69-af12-44dc-ec8e-95005b74179c"
   },
   "outputs": [],
   "source": [
    "resultlist = []\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    if i == NUM_FRAMES:\n",
    "        break\n",
    "    i = i + 1\n",
    "    image = image[:, :, (2, 1, 0)]  # convert from RGB to BGR\n",
    "    original_image = copy.deepcopy(image)\n",
    "    height, width, _ = original_image.shape\n",
    "\n",
    "    # Resize the image to network input shape\n",
    "    input_image = transform(image)\n",
    "    if i == 1:\n",
    "        net.reshape({input_key: input_image.shape})\n",
    "        exec_net = ie.load_network(network=net, device_name=device)\n",
    "\n",
    "    result = exec_net.infer(inputs={input_key: input_image})[output_key].squeeze(0)\n",
    "\n",
    "    resultlist.append((original_image, result))\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Inference of {i} frames took {duration:.3f} seconds\")\n",
    "print(f\"{model_name} - latency: {duration/NUM_FRAMES:.2f} sec., fps: {NUM_FRAMES/duration:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-elite",
   "metadata": {
    "id": "planned-hands"
   },
   "source": [
    "### Write monodepth video to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-probability",
   "metadata": {
    "id": "endangered-constraint"
   },
   "outputs": [],
   "source": [
    "def normalize_minmax(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-insured",
   "metadata": {
    "id": "phantom-powell"
   },
   "outputs": [],
   "source": [
    "result_video_path = f\"{video_path[:-len(video_ext)]}_monodepth_{model_name}.avi\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "out_video = cv2.VideoWriter(\n",
    "    result_video_path,\n",
    "    cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\"),\n",
    "    cap.get(cv2.CAP_PROP_FPS),\n",
    "    (width * 2, height),\n",
    ")\n",
    "cap.release()\n",
    "for originalframe, resultframe in resultlist:\n",
    "    videoframe = normalize_minmax(resultframe)\n",
    "    videoframe = matplotlib.cm.viridis(videoframe)[:, :, :3] * 255\n",
    "\n",
    "    videoframe = videoframe.astype(np.uint8)\n",
    "    videoframe = cv2.resize(videoframe, (width, height))\n",
    "\n",
    "    stacked_frame = np.hstack((originalframe[:, :, (2, 1, 0)], videoframe))\n",
    "    out_video.write(stacked_frame)\n",
    "out_video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-particular",
   "metadata": {
    "id": "bZ89ZI369KjA"
   },
   "source": [
    "### Display monodepth video\n",
    "\n",
    "DEBUG: Colab requires compressing the video before displaying it. See https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-col\n",
    "This requires ffmpeg. For webinar we will not require this.ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-particle",
   "metadata": {
    "id": "incident-minutes"
   },
   "outputs": [],
   "source": [
    "compressed_video_path = result_video_path + \"_compressed.mp4\"\n",
    "! ffmpeg -i $result_video_path -vcodec libx264 $compressed_video_path -hide_banner -loglevel error -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-cotton",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "8PqOn6Dfgik5",
    "outputId": "463d03d1-95d2-46f9-9dba-04bc1c348dd9"
   },
   "outputs": [],
   "source": [
    "mp4 = open(compressed_video_path, \"rb\").read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=1200 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"\n",
    "    % data_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-palace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "monodepth.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "openvino_env_test",
   "language": "python",
   "name": "openvino_env_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
