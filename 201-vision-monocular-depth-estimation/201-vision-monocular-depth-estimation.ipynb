{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "double-provision",
   "metadata": {
    "id": "moved-collapse"
   },
   "source": [
    "# MONODEPTH on OpenVINO IR Model\n",
    "\n",
    "WORK IN PROGRESS NOTEBOOK NOT FOR PUBLIC RELEASE\n",
    "\n",
    "This notebook demonstrates Monocular Depth Estimation with the MidasNet model in OpenVINO. https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/midasnet/midasnet.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-mechanics",
   "metadata": {
    "id": "creative-cisco"
   },
   "source": [
    "## Preparation \n",
    "\n",
    "### Install required Python\\* packages\n",
    "\n",
    "Install the required Python\\* packages by executing `pip install -r requirements.txt` in a terminal, in the directory that contains this notebook. See the [README](https://github.com/helena-intel/openvino-notebooks/blob/develop/README.md) for more details and instructions for how to set up a virtual environment. \n",
    "\n",
    "You can also uncomment and run the cell below to install these requirements. Note that installation may take a while. There is no progress indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-oxygen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grand-monster",
    "outputId": "ffdf9a92-f4f2-44cb-c0f8-780a64320167"
   },
   "outputs": [],
   "source": [
    "# # OpenVINO\n",
    "# !pip install --quiet --index-url https://test.pypi.org/simple --extra-index-url https://pypi.org/simple openvino-dev\n",
    "# # Other packages\n",
    "# !pip install --quiet matplotlib pytube Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-pursuit",
   "metadata": {
    "id": "faced-honolulu"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-state",
   "metadata": {
    "id": "ahead-spider"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import urllib\n",
    "from base64 import b64encode\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "from openvino.inference_engine import IECore\n",
    "from PIL import Image\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-municipality",
   "metadata": {
    "id": "contained-office"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-video",
   "metadata": {
    "id": "amber-lithuania"
   },
   "outputs": [],
   "source": [
    "precision = \"FP16\"\n",
    "device = \"CPU\"\n",
    "MODEL_DIR = \"models\"\n",
    "model_url = \"https://officemacros.nl/midasnet.xml\"  # DEBUG: this should be moved to an official download link\n",
    "\n",
    "model_name = os.path.basename(model_url)\n",
    "model_xml_path = Path(MODEL_DIR) / model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-storm",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-closure",
   "metadata": {
    "id": "endangered-constraint"
   },
   "outputs": [],
   "source": [
    "def normalize_minmax(data):\n",
    "    \"\"\"Normalizes the values in `data` between 0 and 1\"\"\"\n",
    "    return (data - data.min()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ir_model(model_xml_url, directory):\n",
    "    \"\"\"\n",
    "    Downloads IR model from `model_xml_url` and save it to `directory` with the same filename. The directory will be\n",
    "    created if it does not exist.\n",
    "    \"\"\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    model_name = os.path.basename(model_xml_url)\n",
    "    model_xml_path = f\"{directory}/{model_name}\"\n",
    "    if not os.path.exists(model_xml_path):\n",
    "        urllib.request.urlretrieve(model_xml_url, model_xml_path)\n",
    "        urllib.request.urlretrieve(model_xml_url[:-4] + \".bin\", f\"{model_xml_path[:-4]}.bin\")\n",
    "        print(f\"Model {model_name} downloaded to {directory}\")\n",
    "    else:\n",
    "        print(f\"Model {model_name} already exists in {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str):\n",
    "    \"\"\"\n",
    "    Loads an image from `path` and returns it as BGR numpy array. `path` should point to an image file,\n",
    "    either a local filename or an url.\n",
    "    \"\"\"\n",
    "    if path.startswith(\"http\"):\n",
    "        # Set User-Agent to Mozilla because some websites block requests with User-Agent Python\n",
    "        request = urllib.request.Request(path, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        response = urllib.request.urlopen(request)\n",
    "        array = np.asarray(bytearray(response.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(array, -1)  # Loads the image as BGR\n",
    "    else:\n",
    "        image = cv2.imread(path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result_to_image(result, colormap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Convert network result of floating point numbers to an RGB image with integer values from 0-255\n",
    "    by applying a colormap.\n",
    "\n",
    "    `result` is expected to be a single network result in 1,H,W shape\n",
    "    `colormap` is a matplotlib colormap. See https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "    \"\"\"\n",
    "    cmap = matplotlib.cm.get_cmap(colormap)\n",
    "    result = result.squeeze(0)\n",
    "    result = normalize_minmax(result)\n",
    "    result = cmap(result)[:, :, :3] * 255\n",
    "    result = result.astype(np.uint8)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-johnston",
   "metadata": {
    "id": "sensitive-wagner"
   },
   "source": [
    "## Load model and get model information\n",
    "\n",
    "Load the model in Inference Engine with `ie.read_network` and load it to the specified device with `ie.load_network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_ir_model(model_url, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-onion",
   "metadata": {
    "id": "complete-brother"
   },
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(str(model_xml_path), str(model_xml_path.with_suffix(\".bin\")))\n",
    "exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "\n",
    "input_key = list(exec_net.input_info)[0]\n",
    "output_key = list(exec_net.outputs.keys())[0]\n",
    "\n",
    "network_input_shape = exec_net.input_info[input_key].tensor_desc.dims\n",
    "network_image_height, network_image_width = network_input_shape[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-hepatitis",
   "metadata": {
    "id": "compact-bargain"
   },
   "source": [
    "## Monodepth on Image\n",
    "\n",
    "### Load, resize and reshape input image\n",
    "\n",
    "The input image is read with OpenCV, resized to network input size, and reshaped to (N,C,H,W) (H=height, W=width, C=number of channels, N=number of images). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-metallic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "central-psychology",
    "outputId": "d864ee96-3fbd-488d-da1a-88e730f34aad"
   },
   "outputs": [],
   "source": [
    "# Download and load an image\n",
    "# Image source (CC license): https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&r=false&c=%2Fm%2F02rgn06&id=470c2f96cb938855\n",
    "IMAGE_URL = r\"https://officemacros.nl/image.jpg\"  # TODO: move to storage.openvinotoolkit.org\n",
    "\n",
    "image = load_image(IMAGE_URL)\n",
    "resized_image = cv2.resize(image, (network_image_height, network_image_width))  # resize to input shape for network\n",
    "input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)  # reshape image to network input shape NCHW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-oklahoma",
   "metadata": {
    "id": "taken-spanking"
   },
   "source": [
    "### Do inference on image\n",
    "\n",
    "Do the inference, convert the result to an image, and resize it to the original image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-network",
   "metadata": {
    "id": "banner-kruger"
   },
   "outputs": [],
   "source": [
    "result = exec_net.infer(inputs={input_key: input_image})[output_key]\n",
    "# convert network result of disparity map to an image that shows distance as colors\n",
    "result_image = convert_result_to_image(result)\n",
    "# resize back to original image shape. cv2.resize expects shape in (width, height), [::-1] reverses the (height, width) shape to match this.\n",
    "result_image = cv2.resize(result_image, image.shape[:2][::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-worship",
   "metadata": {},
   "source": [
    "### Display monodepth image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-simulation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "ranging-executive",
    "outputId": "30373e8e-34e9-4820-e32d-764aa99d4b25"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 15))\n",
    "ax[0].imshow(image[:, :, (2, 1, 0)])  # (2,1,0) converts the image from BGR to RGB\n",
    "ax[1].imshow(result_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-beads",
   "metadata": {
    "id": "descending-cache"
   },
   "source": [
    "## Monodepth on Video\n",
    "\n",
    "DEBUG: Uses pytube for quickly downloading a video from Youtube.\n",
    "\n",
    "By default, only the first 100 frames are processed, in order to quickly check that everything works. Change NUM_FRAMES in the cell below to modify this. Set NUM_FRAMES to 0 to process the whole video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-providence",
   "metadata": {},
   "source": [
    "### Download and load video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-abraham",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "terminal-dividend",
    "outputId": "87f5ada0-8caf-49c3-fe54-626e2b1967f3"
   },
   "outputs": [],
   "source": [
    "NUM_FRAMES = 100  # Number of video frames to process. Set to 0 to process all frames.\n",
    "VIDEO_URL = \"https://youtu.be/nAcKK6mb_vk\"\n",
    "VIDEO_DIR = \"videos\"\n",
    "\n",
    "# Use PyTube to download a video to VIDEO_DIR\n",
    "yt = YouTube(VIDEO_URL)\n",
    "# Use `yt.streams` to see all available streams. See the PyTube documentation https://python-pytube.readthedocs.io/en/latest/api.html for advanced filtering options\n",
    "stream = yt.streams.filter(resolution=\"360p\").first()\n",
    "stream.download(VIDEO_DIR)\n",
    "\n",
    "# Create Path objects for the input video and the resulting video\n",
    "video_path = Path(VIDEO_DIR) / stream.default_filename\n",
    "result_video_path = video_path.with_name(f\"{video_path.stem}_monodepth.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(str(video_path))\n",
    "_, image = cap.read()\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "FRAME_HEIGHT, FRAME_WIDTH = image.shape[:2]\n",
    "FOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\n",
    "cap.release()\n",
    "\n",
    "print(f\"The input video has a frame width of {FRAME_WIDTH}, frame height of {FRAME_HEIGHT} and runs at {FPS} fps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-sunset",
   "metadata": {},
   "source": [
    "### Do Inference on video and create monodepth video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-appreciation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "present-albany",
    "outputId": "600edb69-af12-44dc-ec8e-95005b74179c"
   },
   "outputs": [],
   "source": [
    "frame_nr = 0\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "out_video = cv2.VideoWriter(\n",
    "    str(result_video_path),\n",
    "    FOURCC,\n",
    "    FPS,\n",
    "    (FRAME_WIDTH * 2, FRAME_HEIGHT),\n",
    ")\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        if NUM_FRAMES != 0 and frame_nr == NUM_FRAMES:\n",
    "            break\n",
    "\n",
    "        # Prepare frame for inference\n",
    "        resized_image = cv2.resize(image, (network_image_height, network_image_width))  # resize to input shape for network\n",
    "        input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)  # reshape image to network input shape NCHW\n",
    "\n",
    "        # Do inference\n",
    "        result = exec_net.infer(inputs={input_key: input_image})[output_key]\n",
    "\n",
    "        # Transform network result to image\n",
    "        result_frame = convert_result_to_image(result)[:, :, (2, 1, 0)]  # Convert result from RGB to BGR\n",
    "        # Resize to original image shape\n",
    "        result_frame = cv2.resize(result_frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        # Put image and result side by side\n",
    "        stacked_frame = np.hstack((image, result_frame))\n",
    "        # Save frame to video\n",
    "        out_video.write(stacked_frame)\n",
    "\n",
    "        frame_nr = frame_nr + 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Processing interrupted.\")\n",
    "finally:\n",
    "    out_video.release()\n",
    "    cap.release()\n",
    "    end_time = time.perf_counter()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Inference of {frame_nr} frames took {duration:.3f} seconds\")\n",
    "    print(\n",
    "        f\"Monodepth Video saved to {VIDEO_DIR} directory. Processed {frame_nr} frames in {duration:.2f} seconds. {frame_nr/duration} frames per second\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-labor",
   "metadata": {
    "id": "bZ89ZI369KjA"
   },
   "source": [
    "### Display monodepth video\n",
    "\n",
    "DEBUG: remove ffmpeg step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-appraisal",
   "metadata": {
    "id": "incident-minutes"
   },
   "outputs": [],
   "source": [
    "compressed_video_path = result_video_path.with_name(f\"{result_video_path.stem}_compressed.mp4\")\n",
    "compressed_video_path_str = str(compressed_video_path)\n",
    "# ! ffmpeg -i \"$result_video_path\" -vcodec libx264 \"$compressed_video_path_str\" -hide_banner -loglevel error -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-brunswick",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "8PqOn6Dfgik5",
    "outputId": "463d03d1-95d2-46f9-9dba-04bc1c348dd9"
   },
   "outputs": [],
   "source": [
    "if compressed_video_path.exists():\n",
    "    mp4 = open(compressed_video_path, \"rb\").read()\n",
    "    data = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    HTML(f\"\"\"<video width=1200 controls  <source sr{data}s\" typ\"=\"video/mp4></video>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "monodepth.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
